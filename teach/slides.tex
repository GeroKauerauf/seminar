% This file provides an example Beamer presentation using the RWTH theme
% showcasing some of the more common options, similar to the Powerpoint version
% 12.11.2014: Revision 1 (Harold Bruintjes, Tim Lange)

% For RWTH, beamer should be loaded with class option t (top)
\documentclass[t]{beamer}

% Use fontspec to get Arial font
% Requires use of XeLaTeX
\usepackage{fontspec}
\setmainfont{Arial}
\setsansfont{Arial}
% Also force Arial for math for a more consistent look
\usepackage{unicode-math}

% https://tex.stackexchange.com/questions/426088/texlive-pretest-2018-beamer-and-subfig-collide
\makeatletter
\let\@@magyar@captionfix\relax
\makeatother

% German style date formatting (footer)
\usepackage[ddmmyyyy]{datetime}
\renewcommand{\dateseparator}{.}

\usepackage{MnSymbol,wasysym}

% Format the captions used for figures etc.
\usepackage[compatibility=false]{caption}
\captionsetup{singlelinecheck=off,justification=raggedleft,labelformat=empty,labelsep=none}

% PGFPlots is used for drawing some of the charts
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\input{plot_commands.tex}

% Load the actual RWTH theme. Suggested is to load the full theme,
% as it requires some specific dimensions
\usetheme{rwth}

% -------------------- My Packages -------------------- %
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage[utf8]{inputenc}
\usepackage{interval}
\usepackage[ngerman]{babel}
\usepackage{csquotes}

% \usepackage{fontspec}
\setmonofont{Roboto Mono}
\usepackage{minted}
\newcommand\pycode[1]{\inputminted[frame=lines, framesep=2mm, fontsize=\normalsize]{python}{#1}}

\definecolor{comment}{HTML}{aaaaaa} % italic
\definecolor{string}{HTML}{448c27}


%---------- Ich bin ein verdammter Künstler ----------
\usepackage{listings}
\definecolor{maroon}{RGB}{128, 0, 0}
\definecolor{pinegreen}{RGB}{1, 121, 111}
\definecolor{darkmidnightblue}{RGB}{0, 51, 102}
\definecolor{rwthblue}{RGB}{0, 84, 159}
% www.colorhexa.com for color references

% ---------- Hyperref -----------
\hypersetup{colorlinks=true,
            breaklinks=true,
            urlcolor=rwthblue,
            linkcolor=rwthblue,
            citecolor=rwthblue}
\def\UrlBreaks{\do\/\do-}
% -------------------------------


\begin{document}
\logo{\includegraphics{logo.png}}

% Setup presentation information
\title{Back-Propagation and Algorithms for Training Artificial Neural Networks with TensorFlow}
\date{11. Dezember 2020}
\author{Gero Kauerauf}

\frame{\titlepage}

\section{Überblick}
% Frame with items
\begin{frame}
    \begin{itemize}
        \item Bildklassifizierung mit TensorFlow.Keras
        \begin{itemize}
            \item Was soll unser Modell können?
            \item Unser Datensatz
            \item Konstruktion unseres Python-Programms
        \end{itemize}
    \end{itemize}
\end{frame}

\section{Was soll unser Modell können?}
\begin{frame}
    \begin{itemize}
        \item Wir möchten ein Modell, welches unterschiedliche Blumen erkennen kann
        \item Wir haben eine Sammlung an von Menschen klassifizierten Bildern von Blumen
        \includegraphics[width=0.5\textwidth]{teach-plots/flower-photos}
        \item Enthalten sind Bilder von Gänseblümchen, Löwenzahn, Rosen, Sonnenblumen und Tuplen
        \item Mit diesem Datensatz können wir ein Modell bauen, welches zwischen genau diesen unterscheiden kann
    \end{itemize}
\end{frame}

\section{Datensatz}
\begin{frame}
    \begin{itemize}
        \item Hier ein kleiner Einblick in unseren Datensatz
    \end{itemize}
    \begin{figure}
        \centering
        \begin{minipage}{0.4\textwidth}
            \centering
            \includegraphics[width=0.8\textwidth]{./teach-plots/dandelion.jpg} % first figure itself
        \end{minipage}\hfill
        \begin{minipage}{0.4\textwidth}
            \centering
            \includegraphics[width=0.5\textwidth]{./teach-plots/rose.jpg} % second figure itself
        \end{minipage}
    \end{figure}
    \begin{figure}
        \centering
        \begin{minipage}{0.4\textwidth}
            \centering
            \includegraphics[width=0.8\textwidth]{./teach-plots/sunflower.jpg} % first figure itself
        \end{minipage}\hfill
        \begin{minipage}{0.4\textwidth}
            \centering
            \includegraphics[width=0.68\textwidth]{./teach-plots/tulip.jpg} % second figure itself
        \end{minipage}
    \end{figure}
\end{frame}

\section{Datensatz}
\begin{frame}
    \begin{itemize}
        \item Zuerst wollen wir unseren Datensatz laden
        \item Dazu definieren wir zuerst die Bildgrößen und die Batch-size
        \pycode{./code-snippets/dataset-params.py}
        \item Danach möchten wir unseren gesammten Datensatz in einen Trainings- und einen Validierungssatz aufteilen
        \item Mit dem Trainingssatz werden wir dann tatsächlich unser MLP trainieren
        \item Den Validierungssatz nutzen wir um unser Modell nach dem Training beurteilen zu können.
    \end{itemize}
\end{frame}

\section{Datensatz}
\begin{frame}
    \begin{itemize}
        \item Dazu nutzen wir die Methode \texttt{image\_dataset\_from\_directory} aus \texttt{tf.keras.preprocessing}
        \pycode{./code-snippets/dataset-from-directory.py}
    \end{itemize}
\end{frame}

\section{Leistungsoptimierung}
\begin{frame}
    \begin{itemize}
        \item Wir werden nun zwei Methoden verwenden um das Laden der Daten beim Training zuverbessern
        \item \texttt{Dataset.cache()}
        \begin{itemize}
            \item Geladene Bilder werden im RAM gelassen und nicht jedes mal erneut eingeladen
        \end{itemize}
        \item \texttt{Dataset.prefetch()}
        \begin{itemize}
            \item Datenvorverarbeitung und Modelltraining werden überlappt
            \item Im \(i\)-ten Trainingsschritt werden die Daten für den den \(i+1\)-ten Schritt gelesen.
        \end{itemize}
    \end{itemize}
\end{frame}

\section{Leistungsoptimierung}
\begin{frame}
    \begin{itemize}
        \item Ohne prefetching
    \end{itemize}
    \includegraphics[width=0.7\textwidth]{teach-plots/naive-prefetching-crop.pdf}
    \begin{itemize}
        \item Mit prefetching
    \end{itemize}
    \includegraphics[width=0.7\textwidth]{teach-plots/prefetched-crop.pdf}
    \large\href{https://www.tensorflow.org/guide/data_performance}{https://www.tensorflow.org/guide/data\_performance}
\end{frame}

\section{Leistungsoptimierung}
\begin{frame}
    \begin{itemize}
        \item Außerdem nutzen wir noch die experimentelle Methode \texttt{AUTOTUNE}
        \item Diese kann die \texttt{buffer\_size} von \texttt{prefetch} dynamisch zur Laufzeit anpassen
        \pycode{./code-snippets/dataset-optimize.py}
        \item Des weiteren ist es in der Praxis von Vorteil die Daten zu standardisieren
        \item Da der RGB-Farbraum das Interval \(\interval{0}{255}\) umfasst, können wir die Daten skalieren, indem wir mit einem Faktor von \(1./255\) multipilizieren
        \item Danach liegen die Werte jedes Pixels in \(\interval{0}{1}\)
        \newline  
        \item Es gibt nur zwei Möglichkeiten
        \begin{itemize}
            \item Wir standardisieren unseren Datensatz
            \item Das erste Layer in unserem Modell standardisiert
        \end{itemize}
        \item Wir entscheiden uns für letztere
    \end{itemize}
\end{frame}

\section{Sequentielles Modell}
\begin{frame}
    \begin{itemize}
        \item Als nächstes wollen wir unser Modell erstellen
        \item Dazu nutzen wir \texttt{tf.keras.Sequential}
        \pycode{./code-snippets/sequential-model-no-aug.py}
    \end{itemize}
\end{frame}

\section{Sequentielles Modell}
\begin{frame}
    \begin{itemize}
        \item Als nächstes konfigurieren wir unser Modell mit \texttt{tf.keras.Sequential.compile}
        \item Hierbei wählen wir den \emph{Optimierer}, die \emph{Fehlerfunktion} und die \emph{Metrik}
        \pycode{./code-snippets/model-compile.py}
        \item \texttt{adam} ist ein stochastisches Gradientenabstiegsverfahren, welches auf adaptiven Schätzungen der Momente ersten und zweiten Grades beruht
        \item \texttt{SparseCategoricalCrossentropy}, da wir mehrere Labels haben, welche durch Integer repräsentiert werden
        \item \texttt{accuracy} berechnet wie häufig die Klassifizierung des Modell mit der tatsächlichen Klasse übereinstimmen
    \end{itemize}
\end{frame}

\section{Training des Modells}
\begin{frame}
    \begin{itemize}
        \item Nachdem wir unseren Datensatz vorbereitet und unser Modell konfiguriert haben, kann nun das Training beginnen
        \newline
        \item Wir trainieren unser Modell 10 Epochen lang
        \item Das bedeutet wir iterieren im Training 10 mal über unseren Datensatz
        \pycode{./code-snippets/model-fit.py}
    \end{itemize}
\end{frame}

\section{Trainingsergebnisse}
\begin{frame}
    \begin{itemize}
        \item Nun möchten wir natürlich sehen wir gut das Training unseres Modells funktioniert hat
        \item Dazu können wir die Trainingsgeschichte mit \texttt{matplotlib} zeichnen
        \pycode{./code-snippets/plot-results.py}
    \end{itemize}
\end{frame}

\section{Trainingsergebnisse}
\begin{frame}
    \begin{itemize}
        \item Die gezeichnete Graphik enthält Informationen über den Verlauf des Trainings
    \end{itemize}
    \begin{figure}
        \begin{minipage}{0.5\textwidth}
            \includegraphics[width=\textwidth]{./teach-plots/pre_augmentation.pdf}
        \end{minipage}\hfill
        \begin{minipage}{0.5\textwidth}
            \begin{itemize}
                \item Die Genauigkeit der Vorhersagen des Modell auf dem Trainingsdatensatz steigt
                \item Die Genauigkeit der Vorhersagen auf dem Validierungssatz stagniert
            \end{itemize}
        \end{minipage}
    \end{figure}
\end{frame}

\section{Overfitting}
\begin{frame}
    \begin{itemize}
        \item Der auftretende Effekt wird Overfitting (dt. Überanpassung) genannt
        \item Aufgrund des kleinen Umfangs unseres Datensatzes lernt das Modell den Trainingsdatensatz im Prinzip \enquote{auswendig}
        \item Es tritt also eine Überanpassung an den Trainingsdatensatz auf, das Modell lernt aus ungewünschten Details der Bilder
        \newline
        \item Wir können unser Modell mit zwei Methoden verbessern
        \begin{itemize}
            \item Data augmentation (dt. Datenerweiterung)
            \item Dropout (dt. Rauswerfen)
        \end{itemize}
    \end{itemize}
\end{frame}

\section{Data augmentation}
\begin{frame}
    \begin{itemize}
        \item Um unseren Datensatz künstlich zu erweitern können wir bereits im Datensatz enthaltene Bilder \enquote{leicht} verändern
        \item Dies ist zum Beispiel durch Spiegeln, Rotation oder Zoomen möglich
        \newline
        \item Dazu können wir drei experimentelle Schichten aus TensorFlow nutzen
        \pycode{./code-snippets/data-aug.py}
    \end{itemize}
\end{frame}

\section{Verbessertes Modell}
\begin{frame}
    \begin{itemize}
        \item Zu unserem verbesserten Modell fügen wir nun noch eine \texttt{tf.keras.layers.Dropout}-Schicht hinzu
        \pycode{./code-snippets/improved-model.py}
    \end{itemize}
\end{frame}

\section{Training des verbesserten Modells}
\begin{frame}
    \begin{itemize}
        \item Nun müssen wir unser verbessertes Modell noch kompilieren
        \pycode{./code-snippets/model-compile.py}
        \item Und trainieren
        \pycode{./code-snippets/improved-model-fit.py}
    \end{itemize}
\end{frame}

\section{Ergebnis der Verbesserung}
\begin{frame}
    \begin{figure}
        \begin{minipage}{0.5\textwidth}
            \begin{itemize}
                \item Vorher.
            \end{itemize}
            \includegraphics[width=\textwidth]{./teach-plots/pre_augmentation.pdf}
        \end{minipage}\hfill
        \begin{minipage}{0.5\textwidth}
            \begin{itemize}
                \item Nachher.
            \end{itemize}
            \includegraphics[width=\textwidth]{./teach-plots/post_augmentation.pdf}
        \end{minipage}
    \end{figure}
\end{frame}

\section{Vorhersagen von neuen Daten}
\begin{frame}
    \begin{itemize}
        \item Nun wollen wir natürlich auch Vorhersagen für beliebige Bilder machen
    \end{itemize}
    \pycode{./code-snippets/predict-new-image.py}
    \begin{minipage}{0.5\textwidth}
        \includegraphics[width=0.75\textwidth]{./teach-plots/592px-Red_sunflower.jpg}
    \end{minipage}\hfill
    \begin{minipage}{0.5\textwidth}
        \begin{itemize}
            \item \textcolor{rwthblue}{Live Demonstration.}
        \end{itemize}
    \end{minipage}
\end{frame}

\section{Fazit}
\begin{frame}
    \begin{itemize}
        \item TensorFlow ist ein \emph{mächtiges} und \enquote{leicht} nutzbares Modul für \textbf{Machine Learning}
        \newline
        \item Quellen
        \begin{itemize}
            \item \href{https://www.tensorflow.org/tutorials/images/classification}{https://www.tensorflow.org/tutorials/images/classification}
            \item \href{https://www.tensorflow.org/api\_docs/python/tf}{https://www.tensorflow.org/api\_docs/python/tf}
            \item \href{https://arxiv.org/pdf/1511.07122.pdf}{https://arxiv.org/pdf/1511.07122.pdf}
        \end{itemize}
    \end{itemize}
\end{frame}

\end{document}
