\subsection{Computational graphs}
\label{sec:computational-graphs}

Another important concept is the one of \emph{computational graphs}.
A \emph{computational graph} describes a mathematical expression.
Such a \emph{directed graph} consists out of nodes and edges.
A node represents an arbitrary variable, that may be a scalar, a vector, a matrix or of any other type.
Then there are also \emph{operations}.
An \emph{operation} can be informally described as a label on a node.
This label defines the operation that is performed on the input.
Whereas the input is given by the \emph{directed edges} to that node.
An operation can take an arbitrary amount of inputs and stores the result in its node.

An example is given by \fref{fig:comp-graph-example}.

\input{./deep-learning/computational-graph-example.tex}
This specific computational graph describes the expression \(H = \max\{0, \fat{W}\fat{x} + \fat{b}\}\), 
where \enquote{relu} refers to the rectifier linear unit function \(f(x) = \max\{0, x\}\).
Therefore this describes the forward propagation of a vector \fat{x} through one layer, where the activation function (\enquote{relu}) is used component-wise as introduced in \fref{sec:feedforward-networks}.