\subsection{Stochastic gradient descent}
\emph{Stochastic gradient descent} (SGD) is the main \emph{optimization algorithm} that is used in \emph{deep learning}.
In \emph{TensorFlow} many of the \emph{optimizers} that come within \emph{keras} are based on the SGD algorithm.

The underlying gradient descent is an iterative optimization algorithm.
Its main idea is to start at an arbitrary point and from there on step into a direction the that minimizes the function value.
This way, it gets closer to a minimum with each step.
Suppose we have a function \(f : \mathbb{R}^2 \rightarrow \mathbb{R}\) that is differentiable.
For any point \(x_0\) we can evaluate its derivative \(f^{\prime}(x_0)\).
And since the derivative describes the slope of the function, it tells us if we have to increase or decrease \(x_0\) in order to make \(f(x_0)\) smaller.

Therefore we can reduce \(f(x)\) by taking a small step into the opposite direction of the derivative \cite{cauchy}, since
\begin{equation}
    \label{eq:cauchy}
    f(x - \epsilon \; \text{sign}(f^{\prime}(x))) < f(x), \qquad \text{for a small enough } \epsilon.
\end{equation}

% Todo make graphic that shows x^2 and 2x and their correlation

What is shown in (fref figure above todo) and \fref{eq:cauchy} can of course be expanded to \(\mathbb{R}^n\).

Let \(x \in \mathbb{R}^n\) and \(f : \mathbb{R}^n \rightarrow \mathbb{R}^m\).
The directional derivative of \(f\) in direction \(u\), a unit vector, is the slope of \(f\) in direction \(u\).
The directional derivative of \(f(x)\) is defined as 
\begin{equation}
    \frac{\partial}{\partial \alpha} f(x + \alpha u) = u^{T} \nabla_x f(x) \big\vert_{\alpha = 0}.
\end{equation}

We would now like to know in which direction \(f\) decreases the fastest.
This can be found out by using the directional derivative.
\begin{align}
      &\min_{u, u^{T}u = 1} u^{T} \nabla_x f(x) \\
    = &\min_{u, u^{T}u = 1} \lVert u \rVert_2 \lVert \nabla_x f(x) \rVert_2 \cos \theta \\
    = &\min_{u, u^{T}u = 1} \lVert \nabla_x f(x) \rVert_2 \cos \theta,
\end{align}
where \(\text{cos } \theta\) is the angle between the gradient and \(u\).
By ignoring the gradient, which does not depend on \(u\), this simplifies further to \(\min_{u} \cos \theta\).
Since \(\cos(\pi) = -1\), this is minimized if the gradient and the unit vector point in opposite directions.
This means the negative gradient points the steepest way downhill.

Therefore taking a step in direction of \(-\nabla_x f(x)\) is an improvement.
It follows that
\begin{equation}
    \lVert f(x - \epsilon \; \nabla_x f(x)) \rVert < \lVert f(x) \rVert, \qquad \text{for a small enough } \epsilon,
\end{equation}
expandes the gradient descent algorithm to arbitrary dimension. This is also called \emph{method of steepest descent}.
Notice that we have to calculate the gradient for each step.
For functions that take a lot of inputs (e.g. DNNs), this is very expensive.

\paragraph{Stochastic gradient descent} takes, as its name proposes, a stochastic approch to avoid the complete calculation of the gradient for functions that can be expressed as a sum.

In the context of training DNNs we often have \emph{loss} functions that decompose into sums.
For example \emph{least squares estimation} essentially describes the sum \(\sum^{n}_{i = 1} (f(x_i) - \tilde{f}(x_i))^2\).

A \emph{minibatch} is a small subset of training examples, usually at maximum just a few hundred, for which we then calculate the gradient.
This means that we basically calculate the gradient for a partial sum of the loss function.
By approximating our gradient this way, we may fit a model onto millions of examples way cheaper. 

Let \(Q(w)\) be a function of the form \(Q(w) = \sum^{n}_{i = 1} Q_i(w)\), where we want to estimate \(w\), so that it minimizes \(Q(w)\).

An estimated gradient for a \emph{minibatch} of size \(m\) could than formed as
\begin{equation}
    \boldsymbol{g} = \eta \nabla \sum^{m}_{i = 1} Q_i(w),
\end{equation}
where \(\eta\) describes the step size, however in the context of deep learning we speak of a \emph{learning rate}.

\begin{algorithm}[H]
    \KwIn{$Q(w) = \sum^{n}_{i = 1} Q_i(w)$}
    \KwOut{$w$ that minimizes $Q(w)$}
    \BlankLine
    Choose initial $w$\;
    \While{$\lVert Q(w) \rVert \geq \epsilon$}{
        Randomly shuffle dataset entries\;
        \For{$i \gets 1$ \KwTo $n$}{
            $w \gets w - \eta \nabla Q_i(w)$\;
        }
    }
    \caption{Stochastic gradient descent}
\end{algorithm}